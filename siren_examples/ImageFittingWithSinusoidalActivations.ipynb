{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we continue our investigation of the **Si**nusoidal **Re**presentation **N**etworks (SIREN)  presented in __*Sitzmann, V., Martel, J., Bergman, A., Lindell, D., & Wetzstein, G. (2020). Implicit neural representations with periodic activation functions. Advances in Neural Information Processing Systems, 33, 7462-7473*.__\n",
        "\n",
        "Here we fit a network with sinusoidal activations to an image.\n"
      ],
      "metadata": {
        "id": "F7OlfKc4eaal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "g05caBL_pMqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we will get an image from the web and construct a dataset from it."
      ],
      "metadata": {
        "id": "uaFpNVezQJT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://cdn.theatlantic.com/thumbor/ISgRyw-VeYqYCE38o7HkVAiz90c=/900x626/media/img/photo/2020/02/photos-superb-owl-sunday-iv/s01_1103328920/original.jpg"
      ],
      "metadata": {
        "id": "3SZOtJ9eatVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image = Image.open('original.jpg')\n",
        "# transform = transforms.Compose([transforms.PILToTensor()])\n",
        "# image = transform(image)\n",
        "# plt.imshow()\n",
        "\n",
        "from matplotlib import image\n",
        "im = image.imread('original.jpg')\n",
        "plt.imshow(im)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "idEp4FvteUdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalization of the image\n",
        "im = torch.tensor(im)\n",
        "nrows, ncols, nchannels = im.shape\n",
        "\n",
        "im = im/255 # \\im in [0,1]\n",
        "rows = torch.arange(0, nrows)\n",
        "cols = torch.arange(0, ncols)\n",
        "\n",
        "rows = 2/(rows[-1] - rows[0]) * ( rows - (rows[-1] + rows[0])/2 )\n",
        "cols = 2/(cols[-1] - cols[0]) * ( cols - (cols[-1] + cols[0])/2 )\n",
        "grid_rows, grid_cols = torch.meshgrid(rows, cols, indexing='ij')\n",
        "\n",
        "X = torch.stack((grid_rows.reshape(-1), grid_cols.reshape(-1)), dim=1)\n",
        "Y = im.view(-1,3)\n",
        "\n",
        "# hardwired 80%-20% training and validation split\n",
        "n1 = int(0.8*nrows*ncols)\n",
        "idx = torch.randperm(nrows*ncols)\n",
        "Xtr, Ytr = X[idx[:n1]], Y[idx[:n1]]\n",
        "Xval, Yval = X[idx[:n1:]], Y[idx[n1:]]\n",
        "\n",
        "train_data = (Xtr, Ytr)\n",
        "val_data = (Xval, Yval)"
      ],
      "metadata": {
        "id": "iZVvYZJMm1EV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.contourf(grid_rows,grid_cols, im.mean(dim=2))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z15TFTPYvPGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Investigating sinusoidal activations\n",
        "\n",
        "Successful training and application of neural networks often requires smart initialization strategies. As noted in the reference above, the same is true when we use sinusoidal activation functions. "
      ],
      "metadata": {
        "id": "DA-PT9hESo-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# modified from https://matplotlib.org/stable/gallery/lines_bars_and_markers/scatter_hist.html\n",
        "\n",
        "def scatter_hist(x, y):\n",
        "\n",
        "  fig = plt.figure()\n",
        "\n",
        "  ax = fig.add_gridspec(top=0.75, right=0.75).subplots()\n",
        "  ax.set(aspect=1)\n",
        "  ax_histx = ax.inset_axes([0, 1.05, 1, 0.25], sharex=ax)\n",
        "  ax_histy = ax.inset_axes([1.05, 0, 0.25, 1], sharey=ax)\n",
        "\n",
        "  # no labels\n",
        "  ax_histx.tick_params(axis=\"x\", labelbottom=False)\n",
        "  ax_histy.tick_params(axis=\"y\", labelleft=False)\n",
        "\n",
        "  # scatter plot\n",
        "  ax.scatter(x, y)\n",
        "  \n",
        "  binwidth = 0.1\n",
        "  xmin = np.min(x)\n",
        "  xmax = np.max(x)\n",
        "  ymin = np.min(y)\n",
        "  ymax = np.max(y)\n",
        "\n",
        "  xbins = np.arange(xmin - 2*binwidth, xmax + 2*binwidth, binwidth)\n",
        "  ybins = np.arange(ymin - 2*binwidth, ymax + 2*binwidth, binwidth)\n",
        "  ax_histx.hist(x, bins=xbins)\n",
        "  ax_histy.hist(y, bins=ybins, orientation='horizontal')\n",
        "\n",
        "  return fig\n"
      ],
      "metadata": {
        "id": "m9Sph9_kd4Ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparison of a sinusoidal activation vs tanh\n",
        "x = torch.arange(-torch.pi,torch.pi,0.01)\n",
        "y_sin = torch.sin(x)\n",
        "y_tanh = torch.tanh(x)\n",
        "plt.plot(x, y_sin, 'r',label='sin')\n",
        "plt.plot(x, y_tanh, 'b',label='tanh')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "biemgsnlPUYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = 2*torch.rand((10000,))-1 # uniform(-1,1)\n",
        "y = torch.sin(torch.pi/2 * x)\n",
        "# not that unlike tanh, the sinusoid does not saturate outside of [-1,1], but rather repeats\n",
        "fig = scatter_hist(x.numpy(),y.numpy())\n",
        "plt.show(fig)"
      ],
      "metadata": {
        "id": "c5HGisYrSoP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = 2*torch.randn((10000,)) #  standard normal\n",
        "y = torch.sin(torch.pi/2 * x)\n",
        "# note that unlike tanh, the sinusoid does not saturate outside of [-1,1]\n",
        "fig = scatter_hist(x.numpy(),y.numpy())\n",
        "plt.show(fig)"
      ],
      "metadata": {
        "id": "LNG7V0zFIYS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fan_in = 100\n",
        "num_samples = 10000\n",
        "c = torch.sqrt( torch.tensor(6)/fan_in)\n",
        "w = 2*c*torch.rand((num_samples, fan_in)) - c # uniform(-c,c)\n",
        "x = 2*torch.rand((num_samples, fan_in,))-1    # uniform(-1,1)\n",
        "\n",
        "preact = (w*x).sum(dim=-1)\n",
        "act = torch.sin(torch.pi/2 * preact )\n",
        "\n",
        "ax1 = plt.subplot(211)\n",
        "ax1.hist(preact, bins = 100)\n",
        "ax2 = plt.subplot(212, sharex=ax1)\n",
        "ax2.hist(act, bins = 100)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZIBo0k-0ELm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the Neural Network"
      ],
      "metadata": {
        "id": "Y377_37cKvSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SinusoidalBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, fan_in, fan_out, w0):\n",
        "      super().__init__()\n",
        "      self.lin = nn.Linear(fan_in, fan_out, bias=True)\n",
        "      self.sin = torch.sin\n",
        "      self.w0 = w0\n",
        "\n",
        "      #adjust inits\n",
        "      c = torch.sqrt(torch.tensor(6))\n",
        "      with torch.no_grad():\n",
        "        if fan_in == 2: #initial block\n",
        "          self.lin.weight *=  self.w0 * c\n",
        "        else:\n",
        "          self.lin.weight *= c\n",
        "        self.lin.bias *= c\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "      x = self.lin(x)\n",
        "      #x = self.sin( torch.pi/2 * x)\n",
        "      x = self.sin(x)\n",
        "      return x\n",
        "\n",
        "\n",
        "class Siren(nn.Module):\n",
        "    \"\"\"\n",
        "    SIREN, i.e., a MLP with sinusoidal activations\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, arch, w0) -> None:\n",
        "      super().__init__()\n",
        "      self.body = nn.Sequential( *(SinusoidalBlock(a,b, w0) for a,b in zip(arch[0:-2], arch[1:-1])) )\n",
        "      self.head = nn.Linear(arch[-2], arch[-1], bias=True)\n",
        "\n",
        "      #adjust inits\n",
        "      with torch.no_grad():\n",
        "        self.head.weight *= torch.sqrt( torch.tensor(6) )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.body(x)\n",
        "        x = self.head(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "2W1NpVp2K3v7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arch = [2, 128, 128, 128, 128, 3]\n",
        "w0 = 30 #note the influence of this value on the prior predictions\n",
        "model = Siren(arch, w0)"
      ],
      "metadata": {
        "id": "0AvjMAVEvfpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prior to training\n",
        "with torch.no_grad():\n",
        "  z = model(X)\n",
        "pred_im = z.view((nrows,ncols,nchannels))\n",
        "#plt.contourf(grid_x, grid_y, pred_im)\n",
        "plt.imshow(pred_im.detach().numpy())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jdLQvpYv0BEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Some default hyperparameters\n",
        "batch_size = 1024\n",
        "max_iters = 20000\n",
        "eval_iters = 100\n",
        "learning_rate = 1e-3\n",
        "weight_decay = 0.0\n",
        "out_freq = 100\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "def loss_func(ypred: torch.Tensor, yb: torch.Tensor) -> torch.Tensor:\n",
        "    # ypred and yb are (B,3)\n",
        "    loss = (ypred-yb)**2\n",
        "    loss.sum(dim=1)\n",
        "    return loss.mean()\n",
        "\n",
        " # Helper function\n",
        "\n",
        "def get_batch(opt):\n",
        "  data = train_data if opt == 'train' else val_data\n",
        "  ix = torch.randint(low = 0, high = data[0].shape[0], size = (batch_size,)) \n",
        "  x = data[0][ix] #create each block at each starting location in ix\n",
        "  y = data[1][ix] #create targets for each block in the batch\n",
        "  x,y = x.to(device), y.to(device)\n",
        "  return x, y \n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss(model):\n",
        "  out = {}\n",
        "  model.eval()\n",
        "  for split in ['train', 'val']:\n",
        "    losses = torch.zeros(eval_iters)\n",
        "    for k in range(eval_iters):\n",
        "      X, Y = get_batch(split)\n",
        "      preds = model(X)\n",
        "      losses[k] = loss(preds,Y).item()\n",
        "    out[split] = losses.mean()\n",
        "  model.train()\n",
        "  return out"
      ],
      "metadata": {
        "id": "k78Y2eTdLHKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "for p in model.parameters():\n",
        "  p.grad = None\n",
        "  p.requires_grad = True\n",
        "\n",
        "lossi = []"
      ],
      "metadata": {
        "id": "BJZHymDwL7WJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "\n",
        "model.train()\n",
        "for iter in range(max_iters):\n",
        "  \n",
        "    xb, yb = get_batch('train')\n",
        "    \n",
        "    pred = model(xb)\n",
        "    loss = loss_func(pred, yb)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # tracking\n",
        "    lossi.append(loss.log10().item())\n",
        "\n",
        "    # outputs\n",
        "    if iter % out_freq == 0:\n",
        "        print(f'iter {iter:7d} | loss  {loss.item():.12f}') \n"
      ],
      "metadata": {
        "id": "u2bOPevOMmq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#so far, the best model seems to have a validation accuracy of around 0.9 (on a chosen batch)\n",
        "plt.plot(torch.tensor(lossi).view(-1,100).mean(dim=1)) "
      ],
      "metadata": {
        "id": "34KIMuFIMybW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  z = model(X)\n",
        "\n",
        "total_loss = loss_func(z,Y)\n",
        "print(f'total loss: {total_loss}')\n",
        "pred_im = z.view((nrows,ncols,nchannels))\n",
        "plt.imshow(pred_im.detach().numpy())\n",
        "plt.show()\n",
        "\n",
        "# the predictions don't quite capture the blur in the background of the original image"
      ],
      "metadata": {
        "id": "fBeqDLox-vBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ReLu network\n",
        "For comparison"
      ],
      "metadata": {
        "id": "J6UXOSkfVWpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReluBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, fan_in, fan_out):\n",
        "      super().__init__()\n",
        "      self.lin = nn.Linear(fan_in, fan_out, bias=True)\n",
        "      self.relu = torch.relu\n",
        "\n",
        "      with torch.no_grad():\n",
        "        self.lin.weight *= 0.01\n",
        "        self.lin.bias += 0.5\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "      x = self.lin(x)\n",
        "      x = self.relu(x)\n",
        "      return x\n",
        "\n",
        "\n",
        "class ReluNet(nn.Module):\n",
        "    \"\"\"\n",
        "    An MLP with relu activations\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, arch) -> None:\n",
        "      super().__init__()\n",
        "      self.body = nn.Sequential( *(ReluBlock(a,b) for a,b in zip(arch[0:-2], arch[1:-1])) )\n",
        "      self.head = nn.Linear(arch[-2], arch[-1], bias=True)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.body(x)\n",
        "        x = self.head(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "GWRbk3SN-_c4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = ReluNet(arch)"
      ],
      "metadata": {
        "id": "X8sQHgvAXLDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prior to training\n",
        "with torch.no_grad():\n",
        "  z = model2(X)\n",
        "pred_im = z.view((nrows,ncols,nchannels))\n",
        "#plt.contourf(grid_x, grid_y, pred_im)\n",
        "plt.imshow(pred_im.detach().numpy())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bv9Yr49MXWVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model2.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "for p in model2.parameters():\n",
        "  p.grad = None\n",
        "  p.requires_grad = True\n",
        "\n",
        "loss2i = []"
      ],
      "metadata": {
        "id": "OgudIcYFXs2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.to(device)\n",
        "\n",
        "model2.train()\n",
        "for iter in range(max_iters):\n",
        "  \n",
        "    xb, yb = get_batch('train')\n",
        "    \n",
        "    pred = model2(xb)\n",
        "    loss = loss_func(pred, yb)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # tracking\n",
        "    loss2i.append(loss.log10().item())\n",
        "\n",
        "    # outputs\n",
        "    if iter % out_freq == 0:\n",
        "        print(f'iter {iter:7d} | loss  {loss.item():.12f}') \n"
      ],
      "metadata": {
        "id": "2Qm10v9SX0k6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.eval()\n",
        "with torch.no_grad():\n",
        "  z = model2(X)\n",
        "\n",
        "total_loss = loss_func(z,Y)\n",
        "print(f'total loss: {total_loss}')\n",
        "pred_im = z.view((nrows,ncols,nchannels))\n",
        "plt.imshow(pred_im.detach().numpy())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MO1oZsUGaQqu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}