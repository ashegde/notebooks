{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we continue our investigation of the **Si**nusoidal **Re**presentation **N**etworks (SIREN)  presented in __*Sitzmann, V., Martel, J., Bergman, A., Lindell, D., & Wetzstein, G. (2020). Implicit neural representations with periodic activation functions. Advances in Neural Information Processing Systems, 33, 7462-7473*.__\n",
        "\n",
        "Here we implement a frequency encoding of the input. We will eventually work towards the multiresolution strategy discussed in __MÃ¼ller, T., Evans, A., Schied, C., & Keller, A. (2022). Instant neural graphics primitives with a multiresolution hash encoding. ACM Transactions on Graphics (ToG), 41(4), 1-15.__\n"
      ],
      "metadata": {
        "id": "F7OlfKc4eaal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "g05caBL_pMqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we will get an image from the web and construct a dataset from it."
      ],
      "metadata": {
        "id": "uaFpNVezQJT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://cdn.theatlantic.com/thumbor/ISgRyw-VeYqYCE38o7HkVAiz90c=/900x626/media/img/photo/2020/02/photos-superb-owl-sunday-iv/s01_1103328920/original.jpg"
      ],
      "metadata": {
        "id": "3SZOtJ9eatVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image = Image.open('original.jpg')\n",
        "# transform = transforms.Compose([transforms.PILToTensor()])\n",
        "# image = transform(image)\n",
        "# plt.imshow()\n",
        "\n",
        "from matplotlib import image\n",
        "im = image.imread('original.jpg')\n",
        "plt.imshow(im)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "idEp4FvteUdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalization of the image\n",
        "im = torch.tensor(im)\n",
        "nrows, ncols, nchannels = im.shape\n",
        "\n",
        "im = im/255 # \\im in [0,1]\n",
        "rows = torch.arange(0, nrows)\n",
        "cols = torch.arange(0, ncols)\n",
        "\n",
        "rows = 2/(rows[-1] - rows[0]) * ( rows - (rows[-1] + rows[0])/2 )\n",
        "cols = 2/(cols[-1] - cols[0]) * ( cols - (cols[-1] + cols[0])/2 )\n",
        "\n",
        "grid_rows, grid_cols = torch.meshgrid(rows, cols, indexing='ij')\n",
        "\n",
        "X = torch.stack((grid_rows.reshape(-1), grid_cols.reshape(-1)), dim=1)\n",
        "Y = im.view(-1,3)\n",
        "\n",
        "# hardwired 80%-20% training and validation split\n",
        "n1 = int(0.8*nrows*ncols)\n",
        "idx = torch.randperm(nrows*ncols)\n",
        "Xtr, Ytr = X[idx[:n1]], Y[idx[:n1]]\n",
        "Xval, Yval = X[idx[:n1:]], Y[idx[n1:]]\n",
        "\n",
        "train_data = (Xtr, Ytr)\n",
        "val_data = (Xval, Yval)"
      ],
      "metadata": {
        "id": "iZVvYZJMm1EV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_im = Y.view((nrows,ncols,nchannels))\n",
        "plt.imshow(pred_im.detach().numpy())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xZNA5onD4_kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Frequency Encoding\n",
        "Contains no trainable parameters"
      ],
      "metadata": {
        "id": "AQqBWbFjFkH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InputEncoding(nn.Module):\n",
        "\n",
        "  def __init__(self,L):\n",
        "    super().__init__()\n",
        "    self.L = L\n",
        "    self.scale = torch.tensor([float(2)**l for l in range(L)])\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    # input: x is (B,D)\n",
        "    # output: (B, D*L)\n",
        "    z = torch.kron(self.scale, x)\n",
        "    out = torch.hstack((torch.sin(z),torch.cos(z)))\n",
        "    return out"
      ],
      "metadata": {
        "id": "KkXyFLr_pf9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the Neural Network"
      ],
      "metadata": {
        "id": "Y377_37cKvSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SinusoidalBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, fan_in, fan_out, w0):\n",
        "      super().__init__()\n",
        "      self.linear = nn.Linear(fan_in, fan_out, bias=True)\n",
        "      self.sin = torch.sin\n",
        "      self.w0 = w0\n",
        "\n",
        "      #adjust inits\n",
        "      c = torch.sqrt(torch.tensor(6))\n",
        "      with torch.no_grad():\n",
        "        if fan_in == 2: #initial block\n",
        "          self.lin.weight *=  self.w0 * c\n",
        "        else:\n",
        "          self.linear.weight *= c\n",
        "        self.linear.bias *= c\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "      x = self.linear(x)\n",
        "      x = self.sin(x)\n",
        "      return x\n",
        "\n",
        "\n",
        "class Siren(nn.Module):\n",
        "    \"\"\"\n",
        "    SIREN, i.e., a MLP with sinusoidal activations\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, arch, w0, L) -> None:\n",
        "      super().__init__()\n",
        "      self.L = L\n",
        "      self.encoding = InputEncoding(L)\n",
        "      self.body = nn.Sequential( *(SinusoidalBlock(a,b, w0) for a,b in zip(arch[0:-2], arch[1:-1])) )\n",
        "      self.head = nn.Linear(arch[-2], arch[-1], bias=True)\n",
        "\n",
        "      #adjust inits\n",
        "      with torch.no_grad():\n",
        "        self.head.weight *= torch.sqrt( torch.tensor(6) )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # x is (B,D)\n",
        "        x = self.encoding(x)\n",
        "        x = self.body(x)\n",
        "        x = self.head(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "2W1NpVp2K3v7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L = 20\n",
        "D = 2\n",
        "arch = [2*D*L, 128, 128, 128, 128, 3]\n",
        "w0 = 30 #note the influence of this value on the prior predictions\n",
        "model = Siren(arch, w0, L)"
      ],
      "metadata": {
        "id": "0AvjMAVEvfpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prior to training\n",
        "with torch.no_grad():\n",
        "  z = model(X)\n",
        "pred_im = z.view((nrows,ncols,nchannels))\n",
        "#plt.contourf(grid_x, grid_y, pred_im)\n",
        "plt.imshow(pred_im.detach().numpy())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jdLQvpYv0BEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Some default hyperparameters\n",
        "batch_size = 1024\n",
        "max_iters = 20000\n",
        "eval_iters = 100\n",
        "learning_rate = 1e-3\n",
        "weight_decay = 0.0\n",
        "out_freq = 100\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "def loss_func(ypred: torch.Tensor, yb: torch.Tensor) -> torch.Tensor:\n",
        "    # ypred and yb are (B,3)\n",
        "    loss = (ypred-yb)**2\n",
        "    loss.sum(dim=1)\n",
        "    return loss.mean()\n",
        "\n",
        " # Helper function\n",
        "\n",
        "def get_batch(opt):\n",
        "  data = train_data if opt == 'train' else val_data\n",
        "  ix = torch.randint(low = 0, high = data[0].shape[0], size = (batch_size,)) \n",
        "  x = data[0][ix] #create each block at each starting location in ix\n",
        "  y = data[1][ix] #create targets for each block in the batch\n",
        "  x,y = x.to(device), y.to(device)\n",
        "  return x, y \n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss(model):\n",
        "  out = {}\n",
        "  model.eval()\n",
        "  for split in ['train', 'val']:\n",
        "    losses = torch.zeros(eval_iters)\n",
        "    for k in range(eval_iters):\n",
        "      X, Y = get_batch(split)\n",
        "      preds = model(X)\n",
        "      losses[k] = loss(preds,Y).item()\n",
        "    out[split] = losses.mean()\n",
        "  model.train()\n",
        "  return out"
      ],
      "metadata": {
        "id": "k78Y2eTdLHKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "for p in model.parameters():\n",
        "  p.grad = None\n",
        "  p.requires_grad = True\n",
        "\n",
        "lossi = []"
      ],
      "metadata": {
        "id": "BJZHymDwL7WJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "\n",
        "model.train()\n",
        "for iter in range(max_iters):\n",
        "  \n",
        "    xb, yb = get_batch('train')\n",
        "    \n",
        "    pred = model(xb)\n",
        "    loss = loss_func(pred, yb)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # tracking\n",
        "    lossi.append(loss.log10().item())\n",
        "\n",
        "    # outputs\n",
        "    if iter % out_freq == 0:\n",
        "        print(f'iter {iter:7d} | loss  {loss.item():.12f}') \n"
      ],
      "metadata": {
        "id": "u2bOPevOMmq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#so far, the best model seems to have a validation accuracy of around 0.9 (on a chosen batch)\n",
        "plt.plot(torch.tensor(lossi).view(-1,100).mean(dim=1)) "
      ],
      "metadata": {
        "id": "34KIMuFIMybW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  z = model(X)\n",
        "\n",
        "total_loss = loss_func(z,Y)\n",
        "print(f'total loss: {total_loss}')\n",
        "pred_im = z.view((nrows,ncols,nchannels))\n",
        "plt.imshow(pred_im.detach().numpy())\n",
        "plt.show()\n",
        "\n",
        "# the predictions don't quite capture the blur in the background of the original image"
      ],
      "metadata": {
        "id": "fBeqDLox-vBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ReLu network\n",
        "For comparison"
      ],
      "metadata": {
        "id": "J6UXOSkfVWpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReluBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, fan_in, fan_out):\n",
        "      super().__init__()\n",
        "      self.lin = nn.Linear(fan_in, fan_out, bias=True)\n",
        "      self.relu = torch.relu\n",
        "\n",
        "      with torch.no_grad():\n",
        "        self.lin.weight *= 0.01\n",
        "        self.lin.bias += 0.5\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "      x = self.lin(x)\n",
        "      x = self.relu(x)\n",
        "      return x\n",
        "\n",
        "\n",
        "class ReluNet(nn.Module):\n",
        "    \"\"\"\n",
        "    An MLP with relu activations\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, arch, L) -> None:\n",
        "      super().__init__()\n",
        "      self.L = L\n",
        "      self.encoding = InputEncoding(L)\n",
        "      self.body = nn.Sequential( *(ReluBlock(a,b) for a,b in zip(arch[0:-2], arch[1:-1])) )\n",
        "      self.head = nn.Linear(arch[-2], arch[-1], bias=True)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.encoding(x)\n",
        "        x = self.body(x)\n",
        "        x = self.head(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "GWRbk3SN-_c4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = ReluNet(arch,L)"
      ],
      "metadata": {
        "id": "X8sQHgvAXLDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prior to training\n",
        "with torch.no_grad():\n",
        "  z = model2(X)\n",
        "pred_im = z.view((nrows,ncols,nchannels))\n",
        "#plt.contourf(grid_x, grid_y, pred_im)\n",
        "plt.imshow(pred_im.detach().numpy())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bv9Yr49MXWVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model2.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "for p in model2.parameters():\n",
        "  p.grad = None\n",
        "  p.requires_grad = True\n",
        "\n",
        "loss2i = []"
      ],
      "metadata": {
        "id": "OgudIcYFXs2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.to(device)\n",
        "\n",
        "model2.train()\n",
        "for iter in range(max_iters):\n",
        "  \n",
        "    xb, yb = get_batch('train')\n",
        "    \n",
        "    pred = model2(xb)\n",
        "    loss = loss_func(pred, yb)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # tracking\n",
        "    loss2i.append(loss.log10().item())\n",
        "\n",
        "    # outputs\n",
        "    if iter % out_freq == 0:\n",
        "        print(f'iter {iter:7d} | loss  {loss.item():.12f}') \n"
      ],
      "metadata": {
        "id": "2Qm10v9SX0k6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.eval()\n",
        "with torch.no_grad():\n",
        "  z = model2(X)\n",
        "\n",
        "total_loss = loss_func(z,Y)\n",
        "print(f'total loss: {total_loss}')\n",
        "pred_im = z.view((nrows,ncols,nchannels))\n",
        "plt.imshow(pred_im.detach().numpy())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MO1oZsUGaQqu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}