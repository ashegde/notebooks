{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3QNtl9z2SGi"
      },
      "source": [
        "In this notebook, we begin our investigation of the **Si**nusoidal **Re**presentation **N**etworks (SIREN)  presented in __*Sitzmann, V., Martel, J., Bergman, A., Lindell, D., & Wetzstein, G. (2020). Implicit neural representations with periodic activation functions. Advances in Neural Information Processing Systems, 33, 7462-7473*.__\n",
        "\n",
        "The intention here is to work our way to neural fields, and hopefully to some PDE applications. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "926fp44j22wI"
      },
      "source": [
        "As a learning excersize, we first implement a simple network using Micrograd.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrMyk7Jl5ML1"
      },
      "source": [
        "#Micrograd implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv1YqN807wLG"
      },
      "source": [
        "*This has been copied over from another notebook, which was based on Karpathy's tutorial.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qw1tvMKo5O8g"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6qVsC5x5UOL"
      },
      "outputs": [],
      "source": [
        "# first we build a data structure to keep track of operations\n",
        "class Value:\n",
        "\n",
        "  def __init__(self, data, _children=(), _op='',label=''):\n",
        "    self.data = data\n",
        "    self.grad = 0.0\n",
        "    self._backward = lambda: None \n",
        "    self._prev = set(_children) #in the forward mode, information propagates from children to parents\n",
        "    self._op = _op\n",
        "    self.label = label\n",
        "\n",
        "  def __repr__(self):\n",
        "    #return f\"Value(data={self.data}, label={self.label})\"\n",
        "    return f\"Value(data={self.data})\"\n",
        "\n",
        "  def __neg__(self): #-self\n",
        "    return self * -1\n",
        "\n",
        "  def __add__(self, other): #order: self + other\n",
        "    other = other if isinstance(other,Value) else Value(other)\n",
        "    out = Value(self.data + other.data, (self, other), _op='+')\n",
        "    def _backward():\n",
        "      self.grad += 1.0 * out.grad\n",
        "      other.grad += 1.0 * out.grad\n",
        "    out._backward = _backward\n",
        "    return out\n",
        "\n",
        "  def __radd__(self, other): #order: other + self\n",
        "    return self + other\n",
        "\n",
        "  def __sub__(self, other): #order: self - other\n",
        "    return self + (-other)\n",
        "\n",
        "  def __mul__(self, other): #order: self * other\n",
        "    other = other if isinstance(other,Value) else Value(other)\n",
        "    out = Value(self.data * other.data, (self, other), _op='*')\n",
        "    def _backward():\n",
        "      self.grad += other.data * out.grad\n",
        "      other.grad += self.data * out.grad\n",
        "    out._backward = _backward\n",
        "    return out\n",
        "  \n",
        "  def __pow__(self,deg):\n",
        "    #assuming other is a constant and not a variable\n",
        "    assert(isinstance(deg, (int, float)), \"only supports powers that are int or float\")\n",
        "    out = Value(self.data ** deg, (self,), _op=f'**{str(deg)}')\n",
        "    def _backward():\n",
        "      self.grad += deg * self.data ** (deg-1)  * out.grad\n",
        "    out._backward = _backward\n",
        "    return out\n",
        "\n",
        "  def __truediv__(self, other): #order: self / other\n",
        "    return self * other**-1\n",
        "\n",
        "  def __rmul__(self,other): # order: other * self (reversed order)\n",
        "    return self*other\n",
        "\n",
        "  def relu(self):\n",
        "    x = self.data\n",
        "    t = x if x > 0 else 0\n",
        "    out = Value(t, (self,), _op = 'relu')\n",
        "    def _backward():\n",
        "      self.grad += 1.0 * out.grad if x > 0 else 0\n",
        "    out._backward = _backward\n",
        "    return out\n",
        "\n",
        "  def tanh(self):\n",
        "    n = self.data\n",
        "    t = (math.exp(2*n) - 1)/(math.exp(2*n)+1)\n",
        "    out = Value(t, (self,), _op='tanh')\n",
        "    def _backward():\n",
        "      self.grad += (1-t**2) * out.grad\n",
        "    out._backward = _backward\n",
        "    return out\n",
        "\n",
        "  def sigmoid(self):\n",
        "    x = self.data\n",
        "    t = 1 / 1-math.exp(-x)\n",
        "    out = Value(t, (self,), _op='sigm')\n",
        "    def _backward():\n",
        "      self.grad += t * (1-t) * out.grad\n",
        "    out._backward = _backward\n",
        "\n",
        "  def sin(self):\n",
        "    x = self.data\n",
        "    t = math.sin(x)\n",
        "    out = Value(t, (self,), _op='sin')\n",
        "    def _backward():\n",
        "      self.grad += math.cos(x) * out.grad\n",
        "    out._backward = _backward\n",
        "    return out\n",
        "\n",
        "  def cos(self):\n",
        "    x = self.data\n",
        "    t = math.cos(x)\n",
        "    out = Value(t, (self,), _op='cos')\n",
        "    def _backward():\n",
        "      self.grad += -math.sin(x) * out.grad\n",
        "    out._backward = _backward\n",
        "    return out\n",
        "\n",
        "  def exp(self):\n",
        "    x = self.data\n",
        "    t = math.exp(x)\n",
        "    out = Value(t, (self,), _op='exp')\n",
        "    def _backward():\n",
        "      self.grad += t * out.grad\n",
        "    out._backward = _backward\n",
        "    return out\n",
        "    \n",
        "  def backward(self):\n",
        "    # build topological order\n",
        "    topo=[]\n",
        "    visited = set()\n",
        "    def build_topo(v):\n",
        "      if v not in visited:\n",
        "        visited.add(v)\n",
        "        for child in v._prev: # all children are added recursively to topo before the parent (v)\n",
        "          build_topo(child)\n",
        "        topo.append(v) #append parent after all children\n",
        "    build_topo(self)\n",
        "    self.grad = 1.0\n",
        "    for node in reversed(topo):\n",
        "      node._backward()\n",
        "\n",
        "  def zero_grad(self):\n",
        "    self.grad = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgQkDZ6y71o5"
      },
      "outputs": [],
      "source": [
        "# visualization\n",
        "from graphviz import Digraph\n",
        "\n",
        "def trace(root): #builds a graph from a Value object\n",
        "  nodes, edges = set(), set()\n",
        "  def build(v):\n",
        "    if v not in nodes:\n",
        "      nodes.add(v)\n",
        "      for child in v._prev:\n",
        "        edges.add((child,v))\n",
        "        build(child)\n",
        "  build(root)\n",
        "  return nodes, edges\n",
        "\n",
        "def draw_dot(root): #visualizes graph from value object\n",
        "  dot = Digraph(format='svg', graph_attr={'rankdir': 'LR'}) #LR = left to right\n",
        "\n",
        "  nodes, edges = trace(root)\n",
        "  for n in nodes:\n",
        "    uid = str(id(n))\n",
        "\n",
        "    dot.node(name = uid, label=\"{ %s | data %.4f | grad %.4f }\" % (n.label, n.data, n.grad), shape = 'record')\n",
        "    if n._op:\n",
        "      dot.node(name=uid+n._op, label = n._op)\n",
        "      dot.edge(uid + n._op, uid)\n",
        "  for n1,n2 in edges:\n",
        "    dot.edge(str(id(n1)), str(id(n2))+n2._op)\n",
        "  \n",
        "  return dot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sI-e0owx74YV"
      },
      "outputs": [],
      "source": [
        "#Simple example\n",
        "\n",
        "x1 = Value(2.0, label='x1')\n",
        "x2 = Value(0.0, label='x2')\n",
        "\n",
        "w1 = Value(-3.0, label='w1')\n",
        "w2 = Value(1.0, label='w2')\n",
        "\n",
        "b = Value(6.7, label='b')\n",
        "\n",
        "x1w1 = x1*w1; x1w1.label = 'x1*w1' \n",
        "x2w2 = x2*w2; x2w2.label='x2*w2'\n",
        "\n",
        "x1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label='x1*w1+x2*w2'\n",
        "n = x1w1x2w2+b; n.label='n'\n",
        "o = n.relu(); o.label='o'\n",
        "draw_dot(o)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KzsGjaG8JLt"
      },
      "outputs": [],
      "source": [
        "o.backward()\n",
        "draw_dot(o)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8uVgHAO74dm"
      },
      "outputs": [],
      "source": [
        "class Neuron:\n",
        "\n",
        "  def __init__(self, nin):\n",
        "    self.w = [Value(np.random.uniform(-1,1), label='w') for i in range(nin)]\n",
        "    self.b = Value(np.random.uniform(-1,1), label='b')\n",
        "    self.preact = None\n",
        "\n",
        "  def __call__(self,x):\n",
        "    #w*x+b\n",
        "    out = sum((wi*xi for wi,xi in zip(self.w,x)), self.b)\n",
        "    self.preact = out\n",
        "    return out\n",
        "  \n",
        "  def parameters(self):\n",
        "    return self.w + [self.b] \n",
        "\n",
        "class Layer:\n",
        "\n",
        "  def __init__(self, nin, nout):\n",
        "    self.neurons = [Neuron(nin) for i in range(nout)]\n",
        "    self.outs = None\n",
        "\n",
        "  def __call__(self, x):\n",
        "    outs = [n(x) for n in self.neurons]\n",
        "    self.outs = outs\n",
        "    return outs #outs[0] if len(outs)==1 else outs\n",
        "\n",
        "  def parameters(self):\n",
        "     return [p for neuron in self.neurons for p in neuron.parameters()]\n",
        "\n",
        "class MLP:\n",
        "\n",
        "  def __init__(self, nin, nouts):\n",
        "    sz = [nin] + nouts #prepends nin to list of nouts\n",
        "    self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]\n",
        "\n",
        "  def __call__(self,x):\n",
        "    for layer in self.layers[:-1]: #forward pass through the MLP\n",
        "      x = layer(x)\n",
        "      x = [t.sin() for t in x]\n",
        "    x = self.layers[-1](x)\n",
        "    return x\n",
        "\n",
        "  def parameters(self):\n",
        "    return [p for layer in self.layers for p in layer.parameters()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUvTRK_Q8VDd"
      },
      "outputs": [],
      "source": [
        "# training data\n",
        "dx = 0.05\n",
        "xs = [i*dx for i in range(100)]\n",
        "ys = [1.0 * math.sin(3*x) + x**2 - 5*x for x in xs]\n",
        "\n",
        "num_train = len(xs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvhoOyMA-Bns"
      },
      "outputs": [],
      "source": [
        "n = MLP(1, [20,20,1])\n",
        "\n",
        "#before training\n",
        "ypred = [n([x])[0].data for x in xs]\n",
        "plt.plot(xs,ys, 'bo', label = 'training')\n",
        "plt.plot(xs,ypred, 'r', label='model (pre-training)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95KR4FnvDGrl"
      },
      "outputs": [],
      "source": [
        "# for debugging, looking at pre-activations\n",
        "# d=0\n",
        "# num_neurons = len(n.layers[d].neurons)\n",
        "# preacts = n.layers[d].outs \n",
        "# preacts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JiKQSvz7HEqu"
      },
      "outputs": [],
      "source": [
        "params = [p.data for p in n.parameters()]\n",
        "plt.hist(params)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSl0JC6x8cIG"
      },
      "outputs": [],
      "source": [
        "for k in range(100):\n",
        "  \n",
        "  # forward pass\n",
        "  ypred = [n([x])[0] for x in xs]\n",
        "  loss = 1/num_train * sum((yout-ygt)**2 for ygt, yout in zip(ys,ypred))\n",
        "\n",
        "  #backward pass\n",
        "  for p in n.parameters(): #recall gradients accumulate in the backward pass, so we need to zero out things beforehand\n",
        "    p.grad = 0.0\n",
        "  loss.backward()\n",
        "\n",
        "  #update\n",
        "  for p in n.parameters(): \n",
        "    p.data += -0.1 * p.grad\n",
        "\n",
        "  print(f'step {k} | loss: {loss.data}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUd1QUvdGvUV"
      },
      "outputs": [],
      "source": [
        "params = [p.data for p in n.parameters()]\n",
        "plt.hist(params)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1-l61vzM0vW"
      },
      "outputs": [],
      "source": [
        "#after training\n",
        "ypred = [n([x])[0].data for x in xs]\n",
        "plt.plot(xs,ys, 'bo', label = 'training')\n",
        "plt.plot(xs,ypred, 'r', label='model (pre-training)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}